{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center> <img src=\"https://drive.google.com/uc?id=1lhxv1BbH-a8Q6rFess61EkaYbybrE6M4\" height=\"\"/>\n",
        "</center>\n",
        "\n",
        "<center><h1>Welcome MLflow Crash Course, by DagsHub</h1>\n",
        "\n",
        "<h1>Part 1</h1></center>\n",
        "\n",
        "---\n",
        "\n",
        "## Hello & Welcome to this HandsOn MLFlow Crash Course by DAGsHub! üëã \n",
        "\n",
        "We‚Äôre excited to invite you to join a two-part virtual course, that covers the core functionality of MLflow, with hands-on experience using it!\n",
        "\n",
        "With 243M downloads and 13K stars on GitHub - MLflow is one of the most widely adopted open-source tools for machine learning lifecycle management. It supports live logging of parameters, metrics, and artifacts, in addition to providing a Model Registry with Deployment functionality.\n",
        "\n",
        "We integrated MLflow into DagsHub almost two years ago, providing a zero-configuration remote MLflow Server with built-in access controls, that support MLflow's Tracking, Model Registry, and Deployment functionality. We've dived into its internals, handled many of its specifics, and now we want to share the knowledge we gained with the data science community!\n",
        "\n",
        "The primary goal of this tutorial is to showcase how to **familiarize you with MLFlow and learn to track your experiments better**.\n",
        "\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "<img src=\"https://dragonballz.co.il/wp-content/uploads/2020/12/discord-logo.jpg\" height=\"23\"/> [Discord Channel](https://discord.com/channels/698874030052212737/698874030572437526) | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Linkedin.svg/1200px-Linkedin.svg.png\" height=\"23\"/> [LinkedIn](https://www.linkedin.com/company/dagshub/) | <img src=\"https://help.twitter.com/content/dam/help-twitter/brand/logo.png\" height=\"25\"/> [Twitter](https://twitter.com/TheRealDAGsHub) | <img src=\"https://res-2.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco/plwmuai9t3okgwbuhkho\" height=\"30\"/> [DAGsHub](https://dagshub.com) | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Octicons-mark-github.svg/1200px-Octicons-mark-github.svg.png\" height=\"25\"/> [GitHub](https://github.com/DAGsHub) | <img src=\"\thttps://www.mlflow.org/docs/latest/_static/MLflow-logo-final-black.png\" height=\"30\"/> [MLFlow](https://www.mlflow.org/)\n",
        "\n"
      ],
      "metadata": {
        "id": "iWUkRt7z2hkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are we learning today?\n",
        "- Why do we need MLflow?\n",
        "- What is MLflow?\n",
        "- MLflow Tracking Functionality \n",
        "  - Understanding Runs & Experiments\n",
        "  - Logging Runs & Experiments\n",
        "  - How and where are the runs recorded?\n",
        "- Hands-on Experience using MLflow"
      ],
      "metadata": {
        "id": "lG6_hUNcE4qy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Why do we need MLFlow? ü§å\n",
        "\n",
        "### **The 80/20 of time spent on an ML project** : Is 80 only the data exploration?\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1ZMVUUsVDRaGRD_aIa8E-4lkGFxxo1WGB\" height=\"250\"/>\n",
        "</center>\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1tK9igz88eMHV115R_0jDuzuPBY9GSTRQ\" height=\"300\"/>\n",
        "</center>\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=11QSKrW29sWfD2lPse_hXpYD9Ql6tLQjo\" height=\"300\"/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "w5e-om3x4qeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###üí°**The effort and time spent in logging the experiments, code, parameters, metrics and their outputs is always underestimated.** \n",
        "\n",
        "Do you find yourself doing CTRL-Y multiple times to find that perfect code which gave you an awesome accuracy or confidence score before you messed it up with the new experiment you decided to run? Or the optimal set of hyper parameters that you used for that run?\n",
        "\n",
        "###‚ùì**Another question that arises is of reproducibility of your experiments.**\n",
        "This is how I was trying to structure my experiments using a Notion Table to keep track of them :\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1xD1aR3-yZICt9vMIdIHkATBMBAS6Pcbx\" height=\"\"/>\n",
        "</center>\n",
        "\n",
        "\n",
        "While Notion is a great tool for note keeping, we can‚Äôt say the same when it comes to tracking the machine learning experimentation and workflow. \n",
        "\n",
        "### **In the midst of all this hardship, I discovered MLflow, my savior!**"
      ],
      "metadata": {
        "id": "dtInWfJ_zZ0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö°What is MLFlow?\n",
        "MLflow is an **open-source tool** to manage the machine learning lifecycle. It supports **live logging** of parameters, metrics, metadata, and artifacts when running a machine learning experiment. To manage the post-training stage, it provides a **model registry** with **deployment functionality** to custom serving tools.\n",
        "\n",
        "It was created to :\n",
        "- resolve the hurdles in choosing the best tool out of numerous available.\n",
        "- reduce the complexity in monitoring the experiments.\n",
        "- ease the reproducibility of the¬†results.\n",
        "- cater the need of a standardized mechanism to deploy the model to production.\n",
        "\n",
        "### üéÇ Introduced in June 2018 by Databricks to offer \n",
        "- **Open interface** : Any ML library, algorithm, deployment tool, or language may be used with MLflow.\n",
        "- **Open source** :¬†MLflow is an¬†open source project¬†that users and library developers can extend. \n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1m0uXc3gZff1prgl_-DRfmg5whRwWboFJ\" height=\"\"/>\n",
        "</center>\n",
        "\n",
        "Reference blog to the stats - Click [here](https://www.databricks.com/blog/2018/06/05/introducing-mlflow-an-open-source-machine-learning-platform.html)!"
      ],
      "metadata": {
        "id": "WIU_pHsS5LDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß© Components that MLFlow offers to help you manage your workflow :\n",
        "\n",
        "- **MLflow Tracking -** Helps in logging parameters, code versions, metrics, and artifacts when running your machine learning code\n",
        "- **MLflow Projects**¬†- For packaging reusable data science code.\n",
        "- **MLflow Models**¬†- For packaging machine learning models and deploying them.\n",
        "- **MLflow Registry -** For managing the whole lifespan of an MLflow Model, it provides a centralized model repository, set of APIs, and user interface."
      ],
      "metadata": {
        "id": "HHfth5VnAYr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Today we will be talking about tracking our ML experiments using MLflow. On¬†September¬†27th,¬†in¬†the¬†second¬†part¬†of¬†our¬†Crash¬†Course with Yono,¬†you¬†will¬†explore:\n",
        "\n",
        "1. **Model Registry** - Log and manage your machine learning models with MLflow.\n",
        "2. **Model Deployment** - Deploy your trained model from the MLflow registry to AWS.\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1d-Kn63mo2RwPDsL1ygniHSBFppvl9UiF\" height=\"300\" width=\"\"/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "TwVcMqEEBsgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî•MLflow Tracking Functionality\n"
      ],
      "metadata": {
        "id": "Ft1TaiLVCIzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Runs & Experiments\n",
        "\n",
        "- The **experiment** unit in MLflow can be handled as a \"project\" or as a \"approach\".  \n",
        "- The term **run** merely refers to a run or execution of a code once.\n",
        "\n",
        "*More than one run might be associated with a single experiment.*\n",
        "\n",
        "Each run is an execution of your data science code which records the following:\n",
        "\n",
        "- **Source of execution**: Contains the hash of the commit if the code was pushed to GitHub and the original line of code that was utilized for the run.\n",
        "- **Artifacts**: Artifacts are output files recorded during a run. \n",
        "- **Parameters**: Parameters are stored in the key-value format.\n",
        "- **Metrics:** The evaluation metrics such as RMSE or ROC-AUC are recorded in a run as well."
      ],
      "metadata": {
        "id": "DSePjmf5F8Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How and where are the runs recorded?\n",
        "\n",
        "*Runs of MLflow can be stored locally in files, remotely on a tracking server, or in a database that is compatible with SQLAlchemy.*\n",
        "\n",
        "### Scenario 1: MLflow on localhost\n",
        "- A good first-time technique to get started.\n",
        "- MLflow will create a directory called **./mlruns** on your local system as soon as you import MLflow and log an artifact.\n",
        "- Limitations on collaboration because experiments or results can't be shared with a team.\n",
        "- Tracking UI - To visualize, search and compare runs, as well as download run artifacts or metadata for analysis in other tools by running the command `mlflow ui`.\n",
        "\n",
        "The UI contains the following key features:\n",
        "\n",
        "- Experiment-based run listing and comparison (including run comparison across multiple experiments)\n",
        "- Searching for runs by parameter or metric value\n",
        "- Visualizing run metrics\n",
        "- Downloading run results\n",
        "\n",
        "\\\\\n",
        "\n",
        "### Scenario 2: MLflow on localhost with SQLite\n",
        "\n",
        "The only difference between this process and the previous one is that we use a local database such as SQLite instead of storing runs to files.\n",
        "\n",
        "\\\\\n",
        "\n",
        "### Scenario 3: MLflow on localhost with Tracking Server\n",
        "\n",
        "This scenario is again similar to the first scenario but here, you can setup a remote server using `mlflow server <args>` which will launch the tracking server at the default port 5000.\n",
        "\n",
        "\\\\\n",
        "\n",
        "### Scenario 4: MLflow with remote Tracking Server, backend and artifact stores\n",
        "- The tracking server, backend store, and artifact store may all be located on different hosts in distributed architectures.\n",
        "- The MLflow client communicates with the tracking server through a sequence of REST requests in order to record all runs' MLflow entities. \n",
        "- The MLflow client interacts with the remote Tracking Server and artifact storage host such as AWS using the¬†boto client¬†libraries, and uploads the artifacts to the S3 bucket URI location.\n",
        "- This set up requires DevOps knowledge.\n",
        "\n",
        "\\\\\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1iqhhqw7yT4GjUlpV6IoYLLuy1BeVtDA0\" height=\"300\"/>\n",
        "</center>\n",
        "\n",
        "\\\\\n",
        "\n",
        "### Scenario 5: MLflow Tracking Server enabled with proxied artifact storage access\n",
        "\n",
        "\\\\\n",
        "\n",
        "*In this case, it is not necessary to grant end users direct path access to a remote object store (such as S3, ADL, GCS, or HDFS) for the management of artifact, nor is it necessary for an end user to provide access credentials.* \n",
        "\n",
        "\\\\\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=17ERqAUwx7OUcph3EjPUPL4OoyCwuhh2W\" height=\"300\"/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "LZrJPCBjCIvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Our Code"
      ],
      "metadata": {
        "id": "6E4MGW5-FTE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DagsHub Configurations üê∂\n",
        "\n",
        "\n",
        "#@markdown Enter the username of your DAGsHub account:\n",
        "DAGSHUB_USER_NAME = \"shambhavicodes\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the email for your DAGsHub account:\n",
        "DAGSHUB_EMAIL = \"shambhavimishra26@gmail.com\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "ufslGlHVFYdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLONE = True\n",
        "PULL_GIT = True\n",
        "SET_DVC_USER = True\n",
        "PULL_DVC = True\n",
        "DAGSHUB_REPO_NAME=\"mario_vs_wario\"\n",
        "BRANCH=\"mlflow-101\""
      ],
      "metadata": {
        "id": "uw8Hr_-zFZAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import getpass\n",
        "import datetime\n",
        "\n",
        "r = requests.post('https://dagshub.com/api/v1/user/tokens', \n",
        "                  json={\"name\": f\"colab-token-{datetime.datetime.now()}\"}, \n",
        "                  auth=(DAGSHUB_USER_NAME, getpass.getpass('DAGsHub password:')))\n",
        "r.raise_for_status()\n",
        "DAGSHUB_TOKEN=r.json()['sha1']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afz_9k6FqcI",
        "outputId": "c746e74c-a50b-4609-fee1-fbb60a252a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DAGsHub password:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Migrate the Repo using [DagsHub API](https://dagshub.com/docs/api)"
      ],
      "metadata": {
        "id": "Fg-Q1mtJF0bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "user_data = requests.get(\"https://dagshub.com/api/v1/user/\",auth=(DAGSHUB_USER_NAME,DAGSHUB_TOKEN))\n",
        "user = json.loads(user_data.text)\n",
        "\n",
        "p = {\n",
        "  \"clone_addr\": f\"https://dagshub.com/ShambhaviCodes/{DAGSHUB_REPO_NAME}.git\",\n",
        "  \"repo_name\": f\"{DAGSHUB_REPO_NAME}\",\n",
        "  \"user_id\":user[\"id\"],\n",
        "  \"mirror\": False,\n",
        "  \"visibility\": \"public\",\n",
        "}\n",
        "\n",
        "r = requests.post(\"https://dagshub.com/api/v1/repos/migrate\", data=p, auth=(DAGSHUB_USER_NAME,DAGSHUB_TOKEN))\n",
        "if r.status_code == 201:\n",
        "  print(\"Migration succeeded\")\n",
        "else:\n",
        "  print(\"Migration faild with error:\\n\", r.text)"
      ],
      "metadata": {
        "id": "EoUs9aPUFtgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the Project and Pull the data to Colab Runtime"
      ],
      "metadata": {
        "id": "MU7dNou0F9m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configure Git**"
      ],
      "metadata": {
        "id": "QQsYUtDwGE1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email {DAGSHUB_EMAIL}\n",
        "!git config --global user.name {DAGSHUB_USER_NAME}"
      ],
      "metadata": {
        "id": "NkYJ39OXF7WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone the Repository**"
      ],
      "metadata": {
        "id": "Rd02jjRRGGFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if CLONE:\n",
        "  !git clone -b {BRANCH} https://{DAGSHUB_USER_NAME}:{DAGSHUB_TOKEN}@dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}.git\n",
        "  %cd {DAGSHUB_REPO_NAME}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og48wUBwGASF",
        "outputId": "101eabf8-def6-4796-e9cf-b2f935a9e9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mario_vs_wario'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 43 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n",
            "/content/mario_vs_wario\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install and Configure DVC**"
      ],
      "metadata": {
        "id": "TTjjspauGSh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install dvc>=2.8.1 --quiet\n",
        "\n",
        "# Import DVC package (relevant only when working in a Colab environment)\n",
        "import dvc\n",
        "\n",
        "if SET_DVC_USER:\n",
        "  # General DVC user configuration\n",
        "  !dvc remote modify --local origin auth basic\n",
        "  !dvc remote modify --local origin user {DAGSHUB_USER_NAME}\n",
        "  !dvc remote modify --local origin password {DAGSHUB_TOKEN}\n",
        "\n",
        "if PULL_DVC:\n",
        "  !dvc pull -r origin >& dev_null\n",
        "\n",
        "  # Make sure that all files were pulled\n",
        "  !dvc pull -r origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPiFDLLtGKLj",
        "outputId": "71cf52e7-f3be-4dc8-9a9d-6610ae673edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything is up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üíª Hands-on Experience using MLflow "
      ],
      "metadata": {
        "id": "xfujaAmeGeHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To demo the MLflow functionality, I choose to use [Eryk Lewinson's project](https://dagshub.com/eryk.lewinson/mario_vs_wario_v2), where he's training a model to classify images that hold Mario or Wario.\n",
        "\n",
        "To shorten the running time, I created a new branch that simplifies the pipeline and only holds the training stage with a small subset of the data.\n",
        "\n",
        "The train.py script has two main components:\n",
        "\n",
        "1.   Data loaders for the train, test, and validation set.\n",
        "\n",
        "2.   A small NN model with four layers"
      ],
      "metadata": {
        "id": "7sBsk3NOGhJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚è≥ Install MLflow\n",
        "MLflow is installed using pip. \n",
        "\n",
        "*Note*: MLflow has several types of versions, each with different support. \n",
        "\n",
        "* Install MLflow\n",
        "\n",
        "  `pip install mlflow`\n",
        "\n",
        "* Install MLflow with the experimental MLflow Pipelines component\n",
        "\n",
        "  `pip install mlflow[pipelines]`\n",
        "\n",
        "* Install MLflow with extra ML libraries and 3rd-party tools\n",
        "\n",
        "  `pip install mlflow[extras]`\n",
        "\n",
        "* Install a lightweight version of MLflow\n",
        "    \n",
        "    `pip install mlflow-skinny`"
      ],
      "metadata": {
        "id": "d5DIqa7EGqsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install mlflow --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3grGRw_ZGn1B",
        "outputId": "ae75bb81-d73b-4520-d3d2-1c2d54b751de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.9 MB 236 kB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147 kB 51.5 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77 kB 5.7 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 209 kB 52.8 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79 kB 8.3 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78 kB 7.3 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55 kB 3.1 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59 kB 6.8 MB/s \n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Log Experiments Locally "
      ],
      "metadata": {
        "id": "-anNKKYaGxuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Import MLflow\n"
      ],
      "metadata": {
        "id": "o1vQ19POG30n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will import mlflow to the colab as well as to the train.py where we will later log our runs.\n",
        "import mlflow"
      ],
      "metadata": {
        "id": "ZUX31FEPHRTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Create an Experiment & Get the Experiment ID\n",
        "\n",
        "There are two ways to create an experiment with MLflow :\n",
        "1. Using **CLI** \n",
        "\n",
        "  Command-Line Interface\n",
        "  The MLflow command-line interface (CLI) provides a simple interface to various functionality in MLflow. You can use the CLI to run projects, start the tracking UI, create and list experiments, download run artifacts, serve MLflow Python Function and scikit-learn models, and serve models on Microsoft Azure Machine Learning and Amazon SageMaker.\n",
        "\n",
        "  You can use \n",
        "  ```\n",
        "  mlflow experiments create --experiment-name <experiment_name>\n",
        "  ```\n",
        "  to create a new experiment from the command line.\n",
        "\n",
        "2. Another option is to use the **Python API**\n",
        "\n",
        "```\n",
        "# Create a file - get_env.py under src directory and copy paste the following code snippet into it \n",
        "import mlflow\n",
        "\n",
        "def get_experiment_id():\n",
        "    name = \"mario_wario\"\n",
        "    exp_id = mlflow.create_experiment(name)\n",
        "    print(exp_id)\n",
        "\n",
        "get_experiment_id()  \n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "rzE99ovrHF1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/mario_vs_wario/src/get_env.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXbaGC5CGtP4",
        "outputId": "12e054d7-41f4-46f1-d8b9-a764ca9374c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Allocate the run to the Experiment\n",
        "\n",
        "We start an MLflow run with the command :\n",
        "```\n",
        "with mlflow.start_run(experiment_id=EXPERIMENT_ID):\n",
        "```\n",
        "We will copy paste this to our train.py with the Experiment ID that we obtained from our last code execution."
      ],
      "metadata": {
        "id": "rUeAdt1TI_5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Log Information  \n",
        "\n",
        "We will start by importing MLflow into our notebook or a .py file. Then we can start using the manual logging commands to log parameters, metrics, artifacts, and general using the following methods:\n",
        "\n",
        "* **Parameters**:\n",
        "  * [Single parameter](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param): mlflow.log_param(*key, value*)\n",
        "  * [Multiple parameters](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_params): mlflow.log_params(*dict*)\n",
        "* **Metrics:**\n",
        "  * [Single metric](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric): mlflow.log_metric(*key, value*)\n",
        "  * [Multiple metrics](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metrics): mlflow.log_metrics(*dict*)\n",
        "* **Artifacts**:\n",
        "  * [Single artifact](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_artifact): mlflow.log_artifact(*local_path: str*)\n",
        "* **Text**:\n",
        "  * [Text](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_text): mlflow.log_text(*string*,*local_path: str*)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "***Note***: MLflow has additional logging capabilities, to read more about them please refer to the [MLflow Tracking docs](https://www.mlflow.org/docs/latest/python_api/mlflow.html#module-mlflow)\n",
        "\n",
        "\n",
        "```\n",
        "# Single parameter\n",
        "mlflow.log_param(\"img_size\", IMG_SIZE)\n",
        "\n",
        "# Multiple parameters\n",
        "mlflow.log_params({\n",
        "    \"img_size\": IMG_SIZE,\n",
        "    \"learning_rate\": LR,\n",
        "    \"epochs\": EPOCHS\n",
        "})\n",
        "\n",
        "# Single metric\n",
        "mlflow.log_metric(\"test_set_loss\", test_loss)\n",
        "\n",
        "\n",
        "# Multiple metrics\n",
        "mlflow.log_metrics(\n",
        "    {\n",
        "        \"test_set_loss\": test_loss,\n",
        "        \"test_set_accuracy\": test_accuracy,\n",
        "    }\n",
        ")\n",
        "\n",
        "mlflow.log_artifact(MODELS_DIR)\n",
        "\n",
        "mlflow.log_text(\"Here you can add general inforamtion about the run\",\"run_info.txt\")\n",
        "```"
      ],
      "metadata": {
        "id": "4q_aHvrnIlv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Time to see the magic! üîç"
      ],
      "metadata": {
        "id": "Fuui_bvgKmaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/{DAGSHUB_REPO_NAME}/src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4F11GuVIWIq",
        "outputId": "e45cbf72-7a86-44d2-f1d8-f6cde44cd981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 2 classes.\n",
            "Found 398 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "50/50 [==============================] - 17s 105ms/step - loss: 0.6806 - accuracy: 0.5462 - val_loss: 0.6081 - val_accuracy: 0.6357\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.6194 - accuracy: 0.6100 - val_loss: 0.5707 - val_accuracy: 0.5327\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.5774 - accuracy: 0.6356 - val_loss: 0.5773 - val_accuracy: 0.5754\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.5239 - accuracy: 0.6969 - val_loss: 0.5751 - val_accuracy: 0.6508\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 6s 127ms/step - loss: 0.4708 - accuracy: 0.7675 - val_loss: 0.6255 - val_accuracy: 0.6784\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.4126 - accuracy: 0.8050 - val_loss: 0.6411 - val_accuracy: 0.6508\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.3873 - accuracy: 0.8119 - val_loss: 1.3068 - val_accuracy: 0.5302\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.3079 - accuracy: 0.8675 - val_loss: 1.7993 - val_accuracy: 0.5553\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.3057 - accuracy: 0.8575 - val_loss: 1.9443 - val_accuracy: 0.5327\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.2616 - accuracy: 0.8956 - val_loss: 2.6622 - val_accuracy: 0.5377\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "7/7 [==============================] - 0s 55ms/step - loss: 2.5300 - accuracy: 0.5200\n",
            "Evaluating completed.\n",
            "Saving the model...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore the Files\n",
        "\n",
        "The information will be logged to the `mlruns` directory.\n",
        "\n",
        "In our example the directory will have the following structure: \n",
        "\n",
        "```\n",
        "mlruns\n",
        "‚îî‚îÄ‚îÄ <experiment ID>\n",
        "    ‚îú‚îÄ‚îÄ <Run Hash>\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ artifacts\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_info.txt\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ meta.yaml\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ metrics\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_set_accuracy\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_set_loss\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ params\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ epochs\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_size\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ learning_rate\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ tags\n",
        "    ‚îÇ       ‚îú‚îÄ‚îÄ mlflow.source.git.commit\n",
        "    ‚îÇ       ‚îú‚îÄ‚îÄ mlflow.source.name\n",
        "    ‚îÇ       ‚îú‚îÄ‚îÄ mlflow.source.type\n",
        "    ‚îÇ       ‚îî‚îÄ‚îÄ mlflow.user\n",
        "    ‚îî‚îÄ‚îÄ meta.yaml\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "O_cxp1fcK-7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log Experiments to a Remote Tracking Server\n",
        "\n",
        "\n",
        "The steps for setting up a Remote Tracking Server with a cloud provider is as follows:\n",
        "\n",
        "1. Start by creating an **MLFlow Docker Image** to increase reproducibility. Alternatively, you can install MLFlow via PIP on the server VMs.\n",
        "2. Set up the Cloud Server to store the runs in an SQL table and the artifacts in a bucket.\n",
        "    1. Open a Service Account\n",
        "    2. Set up role and access.\n",
        "    3. Allocate a buket and grant acess to the role.\n",
        "    4. Allocate an SQL-like DB and grant acess to the role.\n",
        "    5. Run the startup script to initialize the VM instance.\n",
        "    6. Configure the machine with the role.\n",
        "\n",
        "3. You may use the instance's external IP to access the MLFlow tracking UI once all of these above components have been installed.\n",
        "\n",
        "----\n",
        "\n",
        "Going through all the above can be a bit of an hassle, even for people with DevOps background. To simplify the process, DagsHub decided to do the MLOps heavy lifting for you.\n",
        "\n",
        "DagsHub provides a free remote MLflow server with every repository. You can log experiments with MLflow to it, view its information under the¬†[experiment tab](https://dagshub.com/docs/feature_guide/discovering_experiments/), and manage your trained models from the full-fledged MLflow UI built into your DagsHub project.\n",
        "\n",
        "When you create a repository on DagsHub, a remote MLflow server is automatically created and configured with the project. The repository's MLflow tracking server will be located at:\n",
        "\n",
        "`https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow`\n",
        "\n",
        "To set the remote server with you machine you need to:\n",
        "1. **Set DagsHub as the remote URI -** \n",
        "  * `mlflow.set_tracking_uri(https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow)`\n",
        "2. **Set-up your credentials as OS variables**:\n",
        "  * `export MLFLOW_TRACKING_USERNAME=<username/token>`\n",
        "  * `export MLFLOW_TRACKING_PASSWORD=<password>`\n",
        "\n",
        "**Congratulations**, you are ready to start logging experiments. \n",
        "\n",
        "Now, when you run your code, you will see new runs appear in the experiment tables!"
      ],
      "metadata": {
        "id": "OrYrefNqLLzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Create a new experiment from the CLI\n",
        "\n",
        "Last time we saw how to create experiments using Python API, let's do it using the CLI this time!"
      ],
      "metadata": {
        "id": "hwYgCo93NYoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mlflow experiments create --experiment-name mlflow-remote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnMkDYHzKxGa",
        "outputId": "2817d1a4-e363-4055-c676-971b2f7d3bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created experiment 'mlflow-remote' with id 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Setting up important environment variables "
      ],
      "metadata": {
        "id": "R7KtpI0tNyNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# TODO: Explain that it's recommended to define this in the code because it's project specific\n",
        "os.environ['MLFLOW_TRACKING_URI']=f\"https://dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}.mlflow\"\n",
        "\n",
        "# Recommended to define as environment variables\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USER_NAME\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN"
      ],
      "metadata": {
        "id": "CSznfaCFNmfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# To be added to code \n",
        "\n",
        "import os\n",
        "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "# Recommended way:\n",
        "# mlflow.set_tracking_uri(https://dagshub.com/{user name}/{repo name}.mlflow))\n",
        "```"
      ],
      "metadata": {
        "id": "X5Qe0SHgN50N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logging & visualizing the runs on remote server"
      ],
      "metadata": {
        "id": "8SBptQ5-zK-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "display(IPython.display.IFrame(f\"https://dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}/experiments/#/\",'100%',600))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "UtbLjJKSzubh",
        "outputId": "9486f93e-eaae-448e-a89b-e624a2490819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f514436b8d0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600\"\n",
              "            src=\"https://dagshub.com/shambhavicodes/mario_vs_wario/experiments/#/\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Re-running the code to see the logs"
      ],
      "metadata": {
        "id": "jbEkavuGzmzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/{DAGSHUB_REPO_NAME}/src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpx81y7-N9i3",
        "outputId": "981b3477-a460-4879-e3da-eb88114df76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 2 classes.\n",
            "Found 398 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "50/50 [==============================] - 17s 97ms/step - loss: 0.6855 - accuracy: 0.5525 - val_loss: 0.5985 - val_accuracy: 0.6281\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.6207 - accuracy: 0.5938 - val_loss: 0.5684 - val_accuracy: 0.6382\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 5s 96ms/step - loss: 0.6202 - accuracy: 0.6000 - val_loss: 0.5726 - val_accuracy: 0.6357\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 5s 93ms/step - loss: 0.6080 - accuracy: 0.5981 - val_loss: 0.5494 - val_accuracy: 0.6457\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.5916 - accuracy: 0.6056 - val_loss: 0.5432 - val_accuracy: 0.6432\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.5833 - accuracy: 0.6094 - val_loss: 0.5425 - val_accuracy: 0.6432\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 5s 95ms/step - loss: 0.5771 - accuracy: 0.6206 - val_loss: 0.5510 - val_accuracy: 0.5930\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.5279 - accuracy: 0.6750 - val_loss: 0.5614 - val_accuracy: 0.5980\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 5s 95ms/step - loss: 0.5294 - accuracy: 0.6975 - val_loss: 0.5571 - val_accuracy: 0.5754\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 5s 95ms/step - loss: 0.5097 - accuracy: 0.7138 - val_loss: 0.5811 - val_accuracy: 0.6106\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.5673 - accuracy: 0.6500\n",
            "Evaluating completed.\n",
            "Saving the model...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging all your information to a run with an Autologger!\n",
        "\n",
        "If you are a forgetful human logger like me who always forgets to log something to the TensorBoard or the outputs, you will probably appreciate this feature the most! \n",
        "\n",
        "Automatic logging allows you to log metrics, parameters, and models without the need for explicit log statements. MLFlow Autologger supports the following libraries :\n",
        "\n",
        "1. Scikit-learn\n",
        "2. TensorFlow and Keras\n",
        "3. Gluon\n",
        "4. XGBoost\n",
        "5. LightGBM\n",
        "6. Statsmodels\n",
        "7. Spark\n",
        "8. Fastai\n",
        "9. Pytorch\n",
        "\n",
        "While you can use `mlflow.autolog()` to enable logging for all the above supported libraries, alternatively you can use library-specific autolog calls for each library, let‚Äôs use the specific autolog call for tensorflow : \n"
      ],
      "metadata": {
        "id": "eV5rLMFT0Jx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add ```mlflow.tensorflow.autolog()``` right above the call ```with mlflow.start_run():``` and re-run your code to see the logged metrics and artifacts with the autologger. "
      ],
      "metadata": {
        "id": "km10q-b90Rid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/{DAGSHUB_REPO_NAME}/src/train.py"
      ],
      "metadata": {
        "id": "HUW257oH2w35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# And you are an MLflow Tracking Ninja! ü•∑\n",
        "\n",
        "\n",
        "**Behold! One more tutorial to go till you become an MLflow Ninja!**\n",
        "\n",
        "I hope that you are comfortable with the MLflow tool now and would consider it as your go-to ML Workflow Management tool just like me! If you have doubts, you run into errors or you would like to share your experience, please feel free to join our Discord and join us as we build our community stronger each day!\n",
        "\n",
        "See you on 27th September where you will learn Model Registery and Deployment with Mlflow (and with my MLflow pro friend, Yono!)"
      ],
      "metadata": {
        "id": "dIO-Angr0vSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqgnUXsc1ZZo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}